{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"3.Multi_Layer_Perceptrons.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"c3QWirgglTmV"},"source":["# Multi-Layer Perceptrons\n","\n","이번 실습에서는 multi-layer perceptron을 이용하여 regression과 classification 문제를 풀어보겠습니다"]},{"cell_type":"code","metadata":{"id":"ADuPU9nUlTmc"},"source":["## 필요한 Library들을 import 합니다\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","## TensorFlow, Keras version 확인\n","print(tf.__version__)\n","print(keras.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I6L7s2DylTmh"},"source":["np.random.seed(777)\n","tf.random.set_seed(777)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DYPXmllWlTmk"},"source":["## Coding Tips\n","\n","#### 1. Hyper Parameter 정하기\n","#### 2. Data 준비(불러오기 or download 등)\n","#### 3. Dataset 구성 (tf.data.Dataset 이용)\n","#### 4. Model 만들기 (Neural Network model)\n","#### 5. Loss function 정의, Optimizer 선택 - model.compile\n","#### 6. Training (Train, Test function 만들기 포함)\n","#### 7. Validation(or Test) 결과 확인\n"]},{"cell_type":"markdown","metadata":{"id":"fsGxhHThlTml"},"source":["## 1. Regression"]},{"cell_type":"markdown","metadata":{"id":"7XLQ8XHtlTmm"},"source":[" ### Boston Housing Dataset\n"," \n"," 보스턴 주택가격 dataset은 다음과 같은 속성을 바탕으로 해당 타운 주택 가격의 중앙값을 예측하는 문제입니다.\n"," - CRIM: 범죄율\n"," - ZN: 25,000 평방피트당 주거지역 비율\n"," - INDUS: 비소매 상업지구 비율\n"," - CHAS: 찰스강에 인접해 있는지 여부(인접:1, 아니면:0)\n"," - NOX: 일산회질소 농도(단위: 0.1ppm)\n"," - RM: 주택당 방의 수\n"," - AGE: 1940년 이전에 건설된 주택의 비율\n"," - DIS: 5개의 보스턴 직업고용센터와의 거리(가중 평균)\n"," - RAD: 고속도로 접근성\n"," - TAX: 재산세율\n"," - PTRATIO: 학생/교사 비율\n"," - B: 흑인 비율\n"," - LSTAT: 하위 계층 비율\n"," \n"," 예측해야하는 것\n"," - MEDV: 타운의 주택가격 중앙값(단위: 1,000달러)"]},{"cell_type":"code","metadata":{"id":"mEI38OfelTmn"},"source":["## Hyper-parameters\n","learning_rate = 0.001\n","N_EPOCHS = 200\n","N_BATCH = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RgquhxvklTmq"},"source":["## Load data\n","boston_housing = keras.datasets.boston_housing"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q9XMQBSulTmu"},"source":["(train_X, train_Y), (test_X, test_Y) = boston_housing.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n3OJQuOdlTmy"},"source":["train_X.shape, train_Y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7uTwMwtklTm1"},"source":["test_X.shape, test_Y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LLdTxDQmlTm4"},"source":["## 첫번째 data의 속성 확인\n","train_X[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4C6bJ61BlTm7"},"source":["## 첫번째 data의 정답\n","train_Y[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LvFwUuDSlTm-"},"source":["## Data preprocessing을 위한 normilzer\n","def Normalizer(data):\n","    mean = data.mean(axis=0)\n","    std = data.std(axis=0)\n","    data -= mean\n","    data /= std\n","    #print(mean, std)\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"52MDv_rflTnB"},"source":["## Data preprocessing\n","train_X = Normalizer(train_X)\n","train_Y = Normalizer(train_Y)\n","test_X = Normalizer(test_X)\n","test_Y = Normalizer(test_Y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-6N06n6lTnE"},"source":["train_X[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZIPdyrJNlTnG"},"source":["train_Y[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"urZpDcYVlTnJ"},"source":["## Dataset\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_X, train_Y)).shuffle(\n","                buffer_size=500).batch(N_BATCH, drop_remainder=True).repeat()\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_X, test_Y)).batch(N_BATCH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B05pBLg-lTnM"},"source":["## Model function\n","def create_model():\n","    model = keras.Sequential()\n","    model.add(keras.layers.Dense(units=32, activation='relu', input_shape=(13,)))\n","    model.add(keras.layers.Dense(units=16, activation='relu'))\n","    model.add(keras.layers.Dense(units=8, activation='relu'))\n","    model.add(keras.layers.Dense(units=1))\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F_LGHIIOlTnP"},"source":["## Create model, compile & summary\n","model = create_model()\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='mse')\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6azI5eZDqC33"},"source":["keras.utils.plot_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W-RD6EJclTnS"},"source":["## Parameters for training\n","steps_per_epoch = train_X.shape[0]//N_BATCH\n","validation_steps = int(np.ceil(test_X.shape[0]/N_BATCH))\n","print(steps_per_epoch, validation_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mE_Tc99clTnV"},"source":["## Training\n","history = model.fit(train_dataset, epochs=N_EPOCHS, steps_per_epoch=steps_per_epoch,\n","         validation_data=test_dataset, validation_steps=validation_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DeZauPnhq3Lh"},"source":["history.history.keys()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"73rMaJ34lTnX"},"source":["## Plot losses\n","plt.plot(history.history['loss'], 'b-', label='loss')\n","plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U17keWj8lTnc"},"source":["## 2. Classification\n","\n","### Fashion MNIST(MNIST) Dataset"]},{"cell_type":"markdown","metadata":{"id":"JSTFuoXDlTnd"},"source":["10개의 범주(category)와 70,000개의 흑백 이미지로 구성된 [패션 MNIST](https://github.com/zalandoresearch/fashion-mnist) 데이터셋을 사용하겠습니다. 이미지는 해상도(28x28 픽셀)가 낮고 다음처럼 개별 옷 품목을 나타냅니다:\n","\n","<table>\n","  <tr><td>\n","    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n","         alt=\"Fashion MNIST sprite\"  width=\"600\">\n","  </td></tr>\n","  <tr><td align=\"center\">\n","    <b>그림</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">패션-MNIST 샘플</a> (Zalando, MIT License).<br/>&nbsp;\n","  </td></tr>\n","</table>\n","\n","패션 MNIST는 컴퓨터 비전 분야의 \"Hello, World\" 프로그램격인 고전 [MNIST](http://yann.lecun.com/exdb/mnist/) 데이터셋을 대신해서 자주 사용됩니다. MNIST 데이터셋은 손글씨 숫자(0, 1, 2 등)의 이미지로 이루어져 있습니다. 여기서 사용하려는 옷 이미지와 동일한 포맷입니다.\n","\n","패션 MNIST는 일반적인 MNIST 보다 조금 더 어려운 문제이고 다양한 예제를 만들기 위해 선택했습니다. 두 데이터셋은 비교적 작기 때문에 알고리즘의 작동 여부를 확인하기 위해 사용되곤 합니다. 코드를 테스트하고 디버깅하는 용도로 좋습니다.\n","\n","네트워크를 훈련하는데 60,000개의 이미지를 사용합니다. 그다음 네트워크가 얼마나 정확하게 이미지를 분류하는지 10,000개의 이미지로 평가하겠습니다. 패션 MNIST 데이터셋은 텐서플로에서 바로 임포트하여 적재할 수 있습니다:"]},{"cell_type":"markdown","metadata":{"id":"U9Jd24RAlTne"},"source":["이미지는 28x28 크기의 넘파이 배열이고 픽셀 값은 0과 255 사이입니다. *레이블*(label)은 0에서 9까지의 정수 배열입니다. 이 값은 이미지에 있는 옷의 *클래스*(class)를 나타냅니다:\n","\n","<table>\n","  <tr>\n","    <th>레이블</th>\n","    <th>클래스</th>\n","  </tr>\n","  <tr>\n","    <td>0</td>\n","    <td>T-shirt/top</td>\n","  </tr>\n","  <tr>\n","    <td>1</td>\n","    <td>Trouser</td>\n","  </tr>\n","    <tr>\n","    <td>2</td>\n","    <td>Pullover</td>\n","  </tr>\n","    <tr>\n","    <td>3</td>\n","    <td>Dress</td>\n","  </tr>\n","    <tr>\n","    <td>4</td>\n","    <td>Coat</td>\n","  </tr>\n","    <tr>\n","    <td>5</td>\n","    <td>Sandal</td>\n","  </tr>\n","    <tr>\n","    <td>6</td>\n","    <td>Shirt</td>\n","  </tr>\n","    <tr>\n","    <td>7</td>\n","    <td>Sneaker</td>\n","  </tr>\n","    <tr>\n","    <td>8</td>\n","    <td>Bag</td>\n","  </tr>\n","    <tr>\n","    <td>9</td>\n","    <td>Ankle boot</td>\n","  </tr>\n","</table>\n","\n","각 이미지는 하나의 레이블에 매핑되어 있습니다. 데이터셋에 *클래스 이름*이 들어있지 않기 때문에 나중에 이미지를 출력할 때 사용하기 위해 별도의 변수를 만들어 저장합니다"]},{"cell_type":"code","metadata":{"id":"fG3DQKuQlTnf"},"source":["## Hyper-parameters\n","learning_rate = 0.001\n","N_EPOCHS = 30\n","N_BATCH = 100\n","N_CLASS = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HXwl2mElTnh"},"source":["## MNIST Dataset #########################################################\n","# mnist = keras.datasets.mnist\n","# class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","##########################################################################\n","\n","## Fashion MNIST Dataset #################################################\n","mnist = keras.datasets.fashion_mnist\n","class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n","##########################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"66ilJSEhlTnj"},"source":["## MNIST dataset load\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iFI4VOBYlTnm"},"source":["## train_images, train_labels의 shape 확인\n","train_images.shape, train_labels.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oNChZYZclTno"},"source":["## test_images, test_labels의 shape 확인\n","test_images.shape, test_labels.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5cSgEig7lTnr"},"source":["## training set의 각 class 별 image 수 확인\n","unique, counts = np.unique(train_labels, axis=-1, return_counts=True)\n","dict(zip(unique, counts))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VRXq8XeNlTnt"},"source":["## test set의 각 class 별 image 수 확인\n","unique, counts = np.unique(test_labels, axis=-1, return_counts=True)\n","dict(zip(unique, counts))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzBb5S8GlTnv"},"source":["N_TRAIN = train_images.shape[0]\n","N_TEST = test_images.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D950PM8QlTny"},"source":["## train_images의 0번 image 화면에 출력\n","plt.figure()\n","plt.imshow(train_images[0], cmap=plt.cm.binary)\n","plt.colorbar()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bv4WpypTlTn1"},"source":["## 25개의 train image와 label 화면에 출력\n","plt.figure(figsize=(15,15))\n","for i in range(25):\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(train_images[i], cmap=plt.cm.binary)\n","    plt.xlabel(class_names[train_labels[i]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMGMXcSzsiGD"},"source":["train_labels[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ogJJHotUlTn3"},"source":["## image를 0~1사이 값으로 만들기 위하여 255로 나누어줌\n","train_images = train_images.astype(np.float32) / 255.\n","test_images = test_images.astype(np.float32) / 255.\n","\n","## one-hot encoding\n","train_labels = keras.utils.to_categorical(train_labels, N_CLASS)\n","test_labels = keras.utils.to_categorical(test_labels, N_CLASS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"izzGS22klTn5"},"source":["## dataset 구성    \n","train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(\n","                buffer_size=100000).batch(N_BATCH).repeat()\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(N_BATCH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DxLmaViWlTn8"},"source":["## model function\n","def create_model():\n","    model = keras.Sequential()\n","    model.add(keras.layers.Flatten(input_shape=(28,28)))\n","    model.add(keras.layers.Dense(256, activation='relu'))\n","    model.add(keras.layers.Dense(128, activation='relu'))\n","    model.add(keras.layers.Dense(10, activation='softmax'))\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QQVFmqRZlTn-"},"source":["## Create model, compile & summary\n","model = create_model()\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8c40XeIOlToA"},"source":["## Parameters for training\n","steps_per_epoch = N_TRAIN//N_BATCH\n","validation_steps = N_TEST//N_BATCH\n","print(steps_per_epoch, validation_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2IjoUqPlToC"},"source":["## Training\n","history = model.fit(train_dataset, epochs=N_EPOCHS, steps_per_epoch=steps_per_epoch, \n","                    validation_data=test_dataset, validation_steps=validation_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PgOa7oflToF"},"source":["model.evaluate(test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AcwCLSLJlToJ"},"source":["## Plot losses\n","plt.plot(history.history['loss'], 'b-', label='loss')\n","plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9CCIrI5RlToN"},"source":["## Plot losses\n","plt.plot(history.history['accuracy'], 'b-', label='acc')\n","plt.plot(history.history['val_accuracy'], 'r--', label='val_acc')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SpBLpASylToP"},"source":["## 결과 확인\n","def plot_image(i, predictions_array, true_label, img):\n","    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","    plt.imshow(img,cmap=plt.cm.binary)\n","\n","    predicted_label = np.argmax(predictions_array)\n","    if predicted_label == true_label:\n","        color = 'blue'\n","    else:\n","        color = 'red'\n","\n","    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n","                                100*np.max(predictions_array),\n","                                class_names[true_label]),\n","                                color=color)\n","\n","def plot_value_array(i, predictions_array, true_label):\n","    predictions_array, true_label = predictions_array[i], true_label[i]\n","    plt.grid(False)\n","    #plt.xticks([])\n","    plt.xticks(range(N_CLASS), class_names, rotation=90)\n","    plt.yticks([])\n","    thisplot = plt.bar(range(N_CLASS), predictions_array, color=\"#777777\")\n","    plt.ylim([0, 1]) \n","    predicted_label = np.argmax(predictions_array)\n"," \n","    thisplot[predicted_label].set_color('red')\n","    thisplot[true_label].set_color('blue')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B75enAOFlToR"},"source":["rnd_idx = np.random.randint(1, N_TEST//N_BATCH)\n","img_cnt = 0\n","for images, labels in test_dataset:\n","    img_cnt += 1\n","    if img_cnt != rnd_idx:\n","        continue\n","    predictions = model(images, training=False)\n","    num_rows = 5\n","    num_cols = 3\n","    num_images = num_rows*num_cols\n","    labels = tf.argmax(labels, axis=-1)\n","    plt.figure(figsize=(3*2*num_cols, 4*num_rows))\n","    plt.subplots_adjust(hspace=1.0)\n","    for i in range(num_images):\n","        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n","        plot_image(i, predictions.numpy(), labels.numpy(), images.numpy())\n","        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n","        plot_value_array(i, predictions.numpy(), labels.numpy())        \n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"irl_lKLclToT"},"source":[""],"execution_count":null,"outputs":[]}]}