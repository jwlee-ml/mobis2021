{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"2.Linear_Regression_Logistic_Regression.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2UIWlNxFbv-X"},"source":["## Google Drive 동기화\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UgboQxcSbv-i"},"source":["## 필요한 Library들을 import 합니다\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","## TensorFlow, Keras version 확인\n","print(tf.__version__)\n","print(keras.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zG3xXoQObv-m"},"source":["# Linear Regression from Text"]},{"cell_type":"code","metadata":{"id":"3THnKFeEbv-n"},"source":["## input file 경로\n","DATA_FILE = '/content/drive/My Drive/mobis2021/data/birth_life_2010.txt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"knfx3mDwbv-q"},"source":["## data preprocessing\n","def read_birth_life_data(filename):\n","    \"\"\"\n","    Read in birth_life_2010.txt and return:\n","    data in the form of NumPy array\n","    n_samples: number of samples\n","    \"\"\"\n","    text = open(filename, 'r').readlines()[1:]\n","    data = [line[:-1].split('\\t') for line in text]\n","    births = [float(line[1]) for line in data]\n","    lifes = [float(line[2]) for line in data]\n","    data = list(zip(births, lifes))\n","    n_samples = len(data)\n","    data = np.asarray(data, dtype=np.float32)\n","    return data, n_samples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ZVwQirg9bv-t"},"source":["data, n_samples = read_birth_life_data(DATA_FILE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"GdCeMK-Zbv-y"},"source":["print(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E2o5py1Pbv-1"},"source":["print(n_samples)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qB5D1qHAbv-4"},"source":["print(data[:,:1].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fs8DnMGpbv-8"},"source":["## Dataset 만들기 - batch size : 1\n","dataset = tf.data.Dataset.from_tensor_slices((data[:,:1], data[:,1:]))\n","dataset = dataset.shuffle(n_samples).batch(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v0R-GR-Ebv_A"},"source":["### Keras Sequential API 사용하여 model 만들기\n","\n","Keras의 sequential API를 사용하면 model을 마치 block 쌓듯이 순차적으로 쌓아서 neural network model을 만들 수 있습니다\n","\n","keras.laysers.Dense API는 1개의 linear layer를 만들어주고 내부에서 weight와 bias를 자동으로 생성합니다\n","\n","만들어진 model은 model.summary()를 통하여 확인할 수 있습니다"]},{"cell_type":"code","metadata":{"id":"6HiuSAlGbv_C"},"source":["## linear regression model function\n","def create_model():\n","    ## Sequential API 사용\n","    model = keras.Sequential()\n","    ## keras.layers.Dense layer - units는 output의 수를 의미함\n","    ## sequential model의 첫번째 layer에는 input_shape을 써줌\n","    model.add(keras.layers.Dense(units=1, input_shape=(1,)))\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iime5Uddbv_E"},"source":["## model 생성\n","model = create_model()\n","## summary 확인\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fr8aqz5sbv_H"},"source":["model.variables"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bOnJQP9xbv_K"},"source":["model.trainable_variables"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KNlMGIEJbv_N"},"source":["## loss function - Mean Squared Error\n","def compute_loss(labels, predictions):\n","    return tf.reduce_mean(tf.square(labels - predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"55A7pwhpbv_R"},"source":["## learning rate & optimizer\n","learning_rate = 0.001\n","optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Batatu1Zbv_U"},"source":["## gradient 계산하여 gradient descent 학습법으로 weight와 bias update\n","def train_on_batch(model, x, y):\n","    with tf.GradientTape() as tape:\n","        predictions = model(x)\n","        loss = compute_loss(y, predictions)\n","    grads = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ROYgTSMbv_W"},"source":["## Training with stochastic gradient descent\n","import time\n","t0 = time.time()\n","\n","n_epoch = 100\n","for epoch in range(n_epoch):\n","    total_loss = 0.\n","    for x, y in dataset:\n","        loss = train_on_batch(model, x, y)\n","        total_loss += loss\n","    print('Epoch {0}: {1}'.format(epoch+1, total_loss/n_samples))\n","\n","t_end = time.time() - t0\n","print('epoch당 걸린 시간: %.3f 초' % (t_end / n_epoch))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RkWPF7-Qbv_Z"},"source":["## 결과 확인\n","w = model.trainable_variables[0]\n","b = model.trainable_variables[1]\n","plt.plot(data[:,0], data[:,1], 'bo', label='Real data')\n","plt.plot(data[:,0], data[:,[0]] * w.numpy() + b.numpy(), 'r', label='Predicted data')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PokIvEXLbv_c"},"source":["### Autograph를 이용한 속도 향상\n","\n","학습 함수를 정적 그래프로 컴파일 해 봅시다. 이를 위해서 해야할 것은 문자 그대로, tf.function이라는 데코레이터를 위에 넣어주는것 뿐입니다"]},{"cell_type":"code","metadata":{"id":"mjljlNU9bv_d"},"source":["## autograph를 이용하여 static graph로 compile\n","@tf.function\n","def train_on_batch(model, x, y):\n","    with tf.GradientTape() as tape:\n","        predictions = model(x)\n","        loss = compute_loss(y, predictions)\n","    grads = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(grads_and_vars=zip(grads, model.trainable_variables))\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvCmD1JXbv_h"},"source":["## Training with stochastic gradient descent\n","t0 = time.time()\n","\n","n_epoch = 100\n","for epoch in range(n_epoch):\n","    total_loss = 0.\n","    for x, y in dataset:\n","        loss = train_on_batch(model, x, y)\n","        total_loss += loss\n","    print('Epoch {0}: {1}'.format(epoch+1, total_loss/n_samples))\n","\n","t_end = time.time() - t0\n","print('epoch당 걸린 시간: %.3f 초' % (t_end / n_epoch))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YoeMtdkbbv_k"},"source":["# Linear Regression using Keras Training API"]},{"cell_type":"code","metadata":{"id":"rA511KwNbv_l"},"source":["## Dataset 만들기 - batch size : 10\n","batch_size = 10\n","dataset = tf.data.Dataset.from_tensor_slices((data[:,:1], data[:,1:]))\n","dataset = dataset.shuffle(n_samples).batch(batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WI4hT3rLbv_n"},"source":["## linear regression model function\n","def create_model():\n","    ## Sequential API 사용\n","    model = keras.Sequential()\n","    ## keras.layers.Dense layer - units는 output의 수를 의미함\n","    ## sequential model의 첫번째 layer에는 input_shape을 써줌\n","    model.add(keras.layers.Dense(units=1, input_shape=(1,)))\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FVWwCaB8bv_q"},"source":["## model 생성\n","model = create_model()\n","## summary 확인\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_uqtRwlmbv_s"},"source":["model.compile()을 이용하여, loss funtion과 optimizer, 평가 metric을 정의할 수 있습니다"]},{"cell_type":"code","metadata":{"id":"B8wtIhPHbv_t"},"source":["## model compile\n","learning_rate = 0.001\n","model.compile(optimizer=keras.optimizers.SGD(learning_rate),\n","             loss='MSE',\n","             metrics=['MSE'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Swilxp99bv_x"},"source":["## 한 epoch이 몇 개의 batch(step)로 구성되는 지 계산\n","steps_per_epoch = n_samples // batch_size\n","print(steps_per_epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ryuqvsC_bv_0"},"source":["n_epoch = 100\n","t0 = time.time()\n","\n","history = model.fit(dataset, epochs=n_epoch, steps_per_epoch=steps_per_epoch)\n","\n","t_end = time.time() - t0\n","print('epoch당 걸린 시간: %.3f 초' % (t_end / n_epoch))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bT6gaqGcbv_4"},"source":["## 결과 확인\n","w = model.trainable_variables[0]\n","b = model.trainable_variables[1]\n","plt.plot(data[:,0], data[:,1], 'bo', label='Real data')\n","plt.plot(data[:,0], data[:,[0]] * w.numpy() + b.numpy(), 'r', label='Predicted data')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zJmh5pSqbv_6"},"source":["결과가 예상과 다르게 나왔다면, 어느 부분이 잘못되었는지 찾아서 고쳐봅시다."]},{"cell_type":"markdown","metadata":{"id":"r9yr5Wj4bv_7"},"source":["# Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"8e7AZWsRbv_8"},"source":["## Pima Indians Diabetes Dataset for Binary Classification\n","\n","This dataset describes the medical records for Pima Indians and whether or not each patient will have an onset of diabetes within five years."]},{"cell_type":"markdown","metadata":{"id":"VDFTYo3Dbv_8"},"source":["이 dataset의 몇가지 주요 항목을 살펴보면 다음과 같습니다\n","\n","- 인스턴스 수 : 768개\n","- 속성 수 : 8가지\n","- 클래스 수 : 2가지\n","\n","8가지 속성(1번~8번)과 결과(9번)의 상세 내용은 다음과 같습니다.\n","\n","1. 임신 횟수\n","2. 경구 포도당 내성 검사에서 2시간 동안의 혈장 포도당 농도\n","3. 이완기 혈압 (mm Hg)\n","4. 삼두근 피부 두겹 두께 (mm)\n","5. 2 시간 혈청 인슐린 (mu U/ml)\n","6. 체질량 지수\n","7. 당뇨 직계 가족력\n","8. 나이 (세)\n","9. 5년 이내 당뇨병이 발병 여부"]},{"cell_type":"code","metadata":{"id":"0HPYqZ_Zbv_9"},"source":["## input file\n","DATA_FILE = '/content/drive/My Drive/mobis2021/data/pima-indians-diabetes.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Te6tso5qbwAA"},"source":["## input file 읽기\n","xy = np.loadtxt(DATA_FILE, delimiter=',', dtype=np.float32)\n","x_train = xy[:, :-1]\n","y_train = xy[:, -1:]\n","\n","print(x_train.shape, y_train.shape)\n","print(xy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"InOJACRAbwAD"},"source":["## data preprocessing을 위한 minmax scaler\n","def MinMaxScaler(data):\n","    ''' Min Max Normalization\n","    Parameters\n","    ----------\n","    data : numpy.ndarray\n","        input data to be normalized\n","        shape: [Batch size, dimension]\n","    Returns\n","    ----------\n","    data : numpy.ndarry\n","        normalized data\n","        shape: [Batch size, dimension]\n","    References\n","    ----------\n","    .. [1] http://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n","    '''\n","    numerator = data - np.min(data, 0)\n","    denominator = np.max(data, 0) - np.min(data, 0)\n","    # noise term prevents the zero division\n","    return numerator / (denominator + 1e-7)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUP0MnHRbwAG"},"source":["## data preprocessing\n","x_train = MinMaxScaler(x_train)\n","print(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eOd-L-V0bwAJ"},"source":["## Hyper parameter 설정\n","## batch size, epoch, learning rate\n","n_data = x_train.shape[0]\n","batch_size = x_train.shape[0]\n","n_epoch = 1000\n","learning_rate = 0.4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9sP8jLKibwAN"},"source":["## dataset 만들기\n","dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1000).batch(batch_size).repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GceHn2w2bwAQ"},"source":["## model 만들기\n","def create_model():\n","    model = keras.Sequential()\n","    model.add(keras.layers.Dense(units=1, activation='sigmoid', input_shape=(8,)))\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LPq9WI_ubwAT"},"source":["## model 생성\n","model = create_model()\n","## summary 확인\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uo0axx-CbwAV"},"source":["## model compile\n","## 1-class logistic regression이므로 loss는 binary cross-entropy 사용, metric은 accuracy\n","model.compile(optimizer=keras.optimizers.SGD(learning_rate),\n","             loss='binary_crossentropy',\n","             metrics=['accuracy', 'MSE'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E72LFFV6bwAX"},"source":["## 한 epoch이 몇 개의 batch(step)로 구성되는 지 계산\n","steps_per_epoch = n_data // batch_size\n","print(steps_per_epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Ny1lGe0YbwAb"},"source":["## Training\n","history = model.fit(dataset, epochs=n_epoch, steps_per_epoch=steps_per_epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"1I8IdTlXbwAg"},"source":["## accuracy 확인\n","## model.evaluate은 정답이 있는 data의 경우(validation set) 결과를 확인할 때 사용함\n","\n","model.evaluate(dataset, steps=steps_per_epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TWPdtYS0bwAk"},"source":["## 정답이 없는 data(test set)의 경우에는 model.predict 사용\n","model.predict(dataset, steps=steps_per_epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-UDgRCibwAm"},"source":["## model.fit, evaluate, predict는 dataset이 아닌 data도 직접 입력으로 받을 수 있음\n","model = create_model()\n","model.compile(optimizer=keras.optimizers.SGD(learning_rate),\n","             loss='binary_crossentropy',\n","             metrics=['accuracy'])\n","model.evaluate(x_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"FdAv4iT0bwAo"},"source":["model.fit(x_train, y_train, batch_size=batch_size, epochs=n_epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bcELVsB9bwAq"},"source":["model.evaluate(x_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YnR3uaGzbwAu"},"source":["## n번째 data에 대한 예측값\n","import random\n","n = random.randrange(n_data)\n","print(n)\n","prediction = model.predict(x_train[[n]])\n","print(prediction)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"go1ZKaaubwAw"},"source":["## n번째 data에 대한 정답\n","label = y_train[n]\n","print(label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jMW0vP97bwA0"},"source":["if (prediction>=0.5) == label:\n","    print(\"correct prediction\")\n","else:\n","    print(\"wrong prediction\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bzl3XFmPbwA2"},"source":[""],"execution_count":null,"outputs":[]}]}