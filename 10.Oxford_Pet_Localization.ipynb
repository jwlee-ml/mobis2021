{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10.Oxford_Pet_Localization.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Do9e8cnKiFhm"},"source":["## library import\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import os\n","import re\n","from PIL import Image\n","import shutil\n","import xml.etree.ElementTree as et\n","from sklearn.model_selection import train_test_split\n","import random\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Rectangle\n","\n","print(tf.__version__)\n","print(keras.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FwbGSntkEqoJ"},"source":["## Data 준비하기"]},{"cell_type":"code","metadata":{"id":"IEsSkAPzjkqt"},"source":["## google drive에서 압축된 dataset download\n","import gdown\n","url = 'https://drive.google.com/uc?id=1dIR9ANjUsV9dWa0pS9J0c2KUGMfpIRG0'\n","fname = 'oxford_pet.zip'\n","gdown.download(url, fname, quiet=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"26RsVgfjk4f5"},"source":["## oxford_pet.zip이 보이는지 확인\n","!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfMOW1tok6jU"},"source":["## 압축풀기\n","!unzip -q oxford_pet.zip -d oxford_pet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7cgzR9Swk70U"},"source":["## 압축이 풀린 directory 확인\n","!ls oxford_pet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fazkGgbzlAw0"},"source":["## directory 정보\n","cur_dir = os.getcwd()\n","data_dir = os.path.join(cur_dir, 'oxford_pet')\n","image_dir = os.path.join(data_dir, 'images')\n","bbox_dir = os.path.join(data_dir, 'annotations', 'xmls')\n","seg_dir = os.path.join(data_dir, 'annotations', 'trimaps')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0EfLhDTqHLU"},"source":["## image file 수 확인\n","image_files = [fname for fname in os.listdir(image_dir) if os.path.splitext(fname)[-1] == '.jpg']\n","print(len(image_files))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FOhlJu6_Ecj8"},"source":["## localization을 위한 annotation이 되어 있는 file의 수 확인\n","bbox_files = [fname for fname in os.listdir(bbox_dir) if os.path.splitext(fname)[-1] == '.xml']\n","len(bbox_files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-A9mBvDQon8a"},"source":["## image file들을 읽어서 channel이 3이 아닌 image는 삭제\n","for image_file in image_files:\n","  image_path = os.path.join(image_dir, image_file)\n","  bbox_file = os.path.splitext(image_file)[0]+'.xml'\n","  bbox_path = os.path.join(bbox_dir, bbox_file)\n","  image = Image.open(image_path)\n","  image_mode = image.mode\n","  if image_mode != 'RGB':\n","    print(image_file, image_mode)\n","    image = np.asarray(image)\n","    print(image.shape)\n","    os.remove(image_path)\n","    try:\n","      os.remove(bbox_path)\n","    except FileNotFoundError:\n","      pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"znKgQwWPqEs5"},"source":["## image file 수 확인\n","image_files = [fname for fname in os.listdir(image_dir) if os.path.splitext(fname)[-1] == '.jpg']\n","print(len(image_files))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RiwM54x6zeqY"},"source":["## localization을 위한 annotation이 되어 있는 file의 수 확인\n","bbox_files = [fname for fname in os.listdir(bbox_dir) if os.path.splitext(fname)[-1] == '.xml']\n","len(bbox_files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZjj198gzg8k"},"source":["class_list = set()\n","for image_file in image_files:\n","    file_name = os.path.splitext(image_file)[0]\n","    class_name = re.sub('_\\d+', '', file_name)\n","    class_list.add(class_name)\n","class_list = list(class_list)\n","print(len(class_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YJpqthm_rq4p"},"source":["class_list.sort()\n","class_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LBrcB1D_54jq"},"source":["class2idx = {cls:idx for idx, cls in enumerate(class_list)}\n","class2idx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wvi-njt757pi"},"source":["## train, validation directory 생성\n","train_dir = os.path.join(data_dir, 'train_xml')\n","val_dir = os.path.join(data_dir, 'val_xml')\n","os.makedirs(train_dir, exist_ok=True)\n","os.makedirs(val_dir, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9awAOVOA6CAe"},"source":["bbox_files[:20]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9vC1-oTvEwK9"},"source":["## TFRecord 만들기"]},{"cell_type":"code","metadata":{"id":"6ADxeVGrys37"},"source":["IMG_SIZE = 224\n","N_BBOX = len(bbox_files)\n","N_TRAIN = 3000\n","N_VAL = N_BBOX - N_TRAIN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQoIKWbfytPq"},"source":["## TFRecord 저장할 directory와 file 경로 설정\n","tfr_dir = os.path.join(data_dir, 'tfrecord')\n","os.makedirs(tfr_dir, exist_ok=True)\n","\n","tfr_train_dir = os.path.join(tfr_dir, 'loc_train.tfr')\n","tfr_val_dir = os.path.join(tfr_dir, 'loc_val.tfr')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0MjxRm8Ky6gz"},"source":["## TFRecord writer 생성\n","writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n","writer_val = tf.io.TFRecordWriter(tfr_val_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J_ndom94ytXR"},"source":["# The following functions can be used to convert a value to a type compatible\n","# with tf.Example.\n","\n","def _bytes_feature(value):\n","  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","  if isinstance(value, type(tf.constant(0))):\n","    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n","  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _float_feature(value):\n","  \"\"\"Returns a float_list from a float / double.\"\"\"\n","  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n","\n","def _int64_feature(value):\n","  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-GiC1YZ7lcZ"},"source":["shuffle_list = list(range(N_BBOX))\n","random.shuffle(shuffle_list)\n","\n","train_idx_list = shuffle_list[:N_TRAIN]\n","val_idx_list = shuffle_list[N_TRAIN:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DikBpr9Ww65h"},"source":["for idx in train_idx_list:\n","  bbox_file = bbox_files[idx]\n","  bbox_path = os.path.join(bbox_dir, bbox_file)\n","\n","  tree = et.parse(bbox_path)\n","  width = float(tree.find('./size/width').text)\n","  height = float(tree.find('.size/height').text)\n","  xmin = float(tree.find('./object/bndbox/xmin').text)\n","  ymin = float(tree.find('./object/bndbox/ymin').text)\n","  xmax = float(tree.find('./object/bndbox/xmax').text)\n","  ymax = float(tree.find('./object/bndbox/ymax').text)\n","  xc = (xmin + xmax) / 2.\n","  yc = (ymin + ymax) / 2.\n","  x = xc / width\n","  y = yc / height\n","  w = (xmax - xmin) / width\n","  h = (ymax - ymin) / height\n","\n","  file_name = os.path.splitext(bbox_file)[0]\n","  image_file = file_name + '.jpg'\n","  image_path = os.path.join(image_dir, image_file)\n","  image = Image.open(image_path)\n","  image = image.resize((IMG_SIZE, IMG_SIZE))\n","  bimage = image.tobytes()\n","\n","  class_name = re.sub('_\\d+', '', file_name)\n","  class_num = class2idx[class_name]\n","\n","  if file_name[0].islower(): # dog\n","    bi_cls_num = 0\n","  else: # cat\n","    bi_cls_num = 1\n","  \n","  example = tf.train.Example(features=tf.train.Features(feature={\n","      'image': _bytes_feature(bimage),\n","      'cls_num': _int64_feature(class_num),\n","      'bi_cls_num': _int64_feature(bi_cls_num),\n","      'x': _float_feature(x),\n","      'y': _float_feature(y),\n","      'w': _float_feature(w),\n","      'h': _float_feature(h)\n","  }))\n","  writer_train.write(example.SerializeToString())\n","\n","writer_train.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HfTv8QUKyNtD"},"source":["for idx in val_idx_list:\n","  bbox_file = bbox_files[idx]\n","  bbox_path = os.path.join(bbox_dir, bbox_file)\n","\n","  tree = et.parse(bbox_path)\n","  width = float(tree.find('./size/width').text)\n","  height = float(tree.find('.size/height').text)\n","  xmin = float(tree.find('./object/bndbox/xmin').text)\n","  ymin = float(tree.find('./object/bndbox/ymin').text)\n","  xmax = float(tree.find('./object/bndbox/xmax').text)\n","  ymax = float(tree.find('./object/bndbox/ymax').text)\n","  xc = (xmin + xmax) / 2.\n","  yc = (ymin + ymax) / 2.\n","  x = xc / width\n","  y = yc / height\n","  w = (xmax - xmin) / width\n","  h = (ymax - ymin) / height\n","\n","  file_name = os.path.splitext(bbox_file)[0]\n","  image_file = file_name + '.jpg'\n","  image_path = os.path.join(image_dir, image_file)\n","  image = Image.open(image_path)\n","  image = image.resize((IMG_SIZE, IMG_SIZE))\n","  bimage = image.tobytes()\n","\n","  class_name = re.sub('_\\d+', '', file_name)\n","  class_num = class2idx[class_name]\n","\n","  if file_name[0].islower(): # dog\n","    bi_cls_num = 0\n","  else: # cat\n","    bi_cls_num = 1\n","  \n","  example = tf.train.Example(features=tf.train.Features(feature={\n","      'image': _bytes_feature(bimage),\n","      'cls_num': _int64_feature(class_num),\n","      'bi_cls_num': _int64_feature(bi_cls_num),\n","      'x': _float_feature(x),\n","      'y': _float_feature(y),\n","      'w': _float_feature(w),\n","      'h': _float_feature(h)\n","  }))\n","  writer_val.write(example.SerializeToString())\n","\n","writer_val.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HZp0s8YTE5Zs"},"source":["## Localization"]},{"cell_type":"code","metadata":{"id":"eQz4UdD_yQWB"},"source":["## Hyper Parameters\n","N_CLASS = len(class_list)\n","N_EPOCHS = 40\n","N_BATCH = 40\n","IMG_SIZE = 224\n","learning_rate = 0.0001\n","steps_per_epoch = N_TRAIN / N_BATCH\n","validation_steps = int(np.ceil(N_VAL / N_BATCH))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfPlRmaByUrJ"},"source":["## tfrecord file을 data로 parsing해주는 function\n","def _parse_function(tfrecord_serialized):\n","    features={'image': tf.io.FixedLenFeature([], tf.string),\n","              'cls_num': tf.io.FixedLenFeature([], tf.int64),\n","              'bi_cls_num': tf.io.FixedLenFeature([], tf.int64),\n","              'x': tf.io.FixedLenFeature([], tf.float32),\n","              'y': tf.io.FixedLenFeature([], tf.float32),\n","              'w': tf.io.FixedLenFeature([], tf.float32),\n","              'h': tf.io.FixedLenFeature([], tf.float32)              \n","             }\n","    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n","    \n","    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)    \n","    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 3])\n","    image = tf.cast(image, tf.float32)/255.\n","\n","    cls_label = tf.cast(parsed_features['cls_num'], tf.int64)\n","    bi_cls_label = tf.cast(parsed_features['bi_cls_num'], tf.int64)\n","    \n","    x = tf.cast(parsed_features['x'], tf.float32)\n","    y = tf.cast(parsed_features['y'], tf.float32)\n","    w = tf.cast(parsed_features['w'], tf.float32)\n","    h = tf.cast(parsed_features['h'], tf.float32)\n","    gt = tf.stack([x, y, w, h], -1)\n","    \n","    return image, gt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sp4sPRxx6CrZ"},"source":["## train dataset 만들기\n","train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n","train_dataset = train_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","train_dataset = train_dataset.shuffle(buffer_size=N_TRAIN).prefetch(\n","    tf.data.experimental.AUTOTUNE).batch(N_BATCH).repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QacNfsYQ6PBH"},"source":["## validation dataset 만들기\n","val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n","val_dataset = val_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","val_dataset = val_dataset.batch(N_BATCH).repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5_CwlDAV6R92"},"source":["## train dataset에서 1개의 image와 bbox를 읽어서 확인\n","for image, gt in val_dataset.take(3):\n","    \n","    '''그림을 그리기 위해서 bbox의 왼쪽 위 꼭지점 좌표를 계산하고, \n","    xmin, ymin, w, h 각각을 image size에 맞게 scaling'''\n","    x = gt[:,0]\n","    y = gt[:,1]\n","    w = gt[:,2]\n","    h = gt[:,3]\n","    xmin = x[0].numpy() - w[0].numpy()/2.\n","    ymin = y[0].numpy() - h[0].numpy()/2.\n","    rect_x = int(xmin * IMG_SIZE)\n","    rect_y = int(ymin * IMG_SIZE)\n","    rect_w = int(w[0].numpy() * IMG_SIZE)\n","    rect_h = int(h[0].numpy() * IMG_SIZE)\n","    \n","    ## 그림 그리기\n","    rect = Rectangle((rect_x, rect_y), rect_w, rect_h, fill=False, color='red')\n","    plt.axes().add_patch(rect)\n","    plt.imshow(image[0])\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2PEnXdaYFCF3"},"source":["### Pretrained MobileNetV2로 Localization 학습하기"]},{"cell_type":"code","metadata":{"id":"leWk69ZH6WXe"},"source":["from tensorflow.keras import optimizers\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n","from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D, Concatenate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gvm67XLr6u7R"},"source":["## MobileNet V2의 pretrained model을 load\n","mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLPN9shk6qi_"},"source":["## localization을 위한 network\n","## mobilenet v2 구조에 fully connected layer 3개를 추가하고 마지막 layer는 4개의 node로 x,y,w,h를 예측하도록 함\n","model = keras.models.Sequential()\n","model.add(mobilenetv2)\n","model.add(GlobalAveragePooling2D())\n","model.add(Dense(256))\n","model.add(BatchNormalization())\n","model.add(ReLU())\n","model.add(Dense(64))\n","model.add(BatchNormalization())\n","model.add(ReLU())\n","model.add(Dense(4, activation='sigmoid'))\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f1QAJA68NMdm"},"source":["def loss_fn(y_true, y_pred):\n","  return keras.losses.MeanSquaredError()(y_true, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O2WDqlVp6smW"},"source":["## learning rate scheduing\n","lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n","                                                          decay_steps=steps_per_epoch*10,\n","                                                          decay_rate=0.5,\n","                                                          staircase=True)\n","## optimizer는 RMSprop, loss는 mean squared error 사용\n","model.compile(optimizers.RMSprop(lr_schedule, momentum=0.9), loss=loss_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0abtefNJ6xJ-"},"source":["## Train!\n","model.fit(train_dataset, steps_per_epoch=steps_per_epoch,\n","         epochs=N_EPOCHS,\n","         validation_data=val_dataset,\n","         validation_steps=validation_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4K693roi6zRm"},"source":["## 예측한 bounding box와 ground truth box를 image에 같이 표시\n","## 정답은 빨간색 box, 예측은 파란색 box\n","idx = 0\n","num_imgs = validation_steps\n","for val_data, val_gt in val_dataset.take(num_imgs):\n","    ## 정답 box 그리기\n","    x = val_gt[:,0]\n","    y = val_gt[:,1]\n","    w = val_gt[:,2]\n","    h = val_gt[:,3]\n","    xmin = x[idx].numpy() - w[idx].numpy()/2.\n","    ymin = y[idx].numpy() - h[idx].numpy()/2.\n","    rect_x = int(xmin * IMG_SIZE)\n","    rect_y = int(ymin * IMG_SIZE)\n","    rect_w = int(w[idx].numpy() * IMG_SIZE)\n","    rect_h = int(h[idx].numpy() * IMG_SIZE)\n","    \n","    rect = Rectangle((rect_x, rect_y), rect_w, rect_h, fill=False, color='red')\n","    plt.axes().add_patch(rect)\n","    \n","    ## 예측 box 그리기\n","    ## validation set에 대해서 bounding box 예측\n","    prediction = model.predict(val_data)\n","    pred_x = prediction[:,0]\n","    pred_y = prediction[:,1]\n","    pred_w = prediction[:,2]\n","    pred_h = prediction[:,3]\n","    pred_xmin = pred_x[idx] - pred_w[idx]/2.\n","    pred_ymin = pred_y[idx] - pred_h[idx]/2.\n","    pred_rect_x = int(pred_xmin * IMG_SIZE)\n","    pred_rect_y = int(pred_ymin * IMG_SIZE)\n","    pred_rect_w = int(pred_w[idx] * IMG_SIZE)\n","    pred_rect_h = int(pred_h[idx] * IMG_SIZE)\n","    \n","    pred_rect = Rectangle((pred_rect_x, pred_rect_y), pred_rect_w, pred_rect_h,\n","                         fill=False, color='blue')\n","    plt.axes().add_patch(pred_rect)\n","    \n","    ## image와 bbox 함께 출력\n","    plt.imshow(val_data[idx])\n","    plt.show()    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sV7MLvizlblo"},"source":["## IOU 계산\n","avg_iou = 0\n","num_imgs = validation_steps\n","res = N_VAL % N_BATCH #5\n","for i, (val_data, val_gt) in enumerate(val_dataset.take(num_imgs)):\n","    ## 정답 box 그리기\n","    flag = (i == validation_steps-1)\n","    x = val_gt[:,0]\n","    y = val_gt[:,1]\n","    w = val_gt[:,2]\n","    h = val_gt[:,3]\n","    prediction = model.predict(val_data)\n","    pred_x = prediction[:,0]\n","    pred_y = prediction[:,1]\n","    pred_w = prediction[:,2]\n","    pred_h = prediction[:,3]\n","    for idx in range(N_BATCH):\n","      if(flag):\n","        if idx == res:\n","          flag = False\n","          break          \n","      xmin = int((x[idx].numpy() - w[idx].numpy()/2.)*IMG_SIZE)\n","      ymin = int((y[idx].numpy() - h[idx].numpy()/2.)*IMG_SIZE)\n","      xmax = int((x[idx].numpy() + w[idx].numpy()/2.)*IMG_SIZE)\n","      ymax = int((y[idx].numpy() + h[idx].numpy()/2.)*IMG_SIZE)\n","\n","      pred_xmin = int((pred_x[idx] - pred_w[idx]/2.)*IMG_SIZE)\n","      pred_ymin = int((pred_y[idx] - pred_h[idx]/2.)*IMG_SIZE)\n","      pred_xmax = int((pred_x[idx] + pred_w[idx]/2.)*IMG_SIZE)\n","      pred_ymax = int((pred_y[idx] + pred_h[idx]/2.)*IMG_SIZE)\n","\n","      if xmin > pred_xmax or xmax < pred_xmin:        \n","        continue\n","      if ymin > pred_ymax or ymax < pred_ymin:        \n","        continue\n","      w_union = np.max((xmax, pred_xmax)) - np.min((xmin, pred_xmin))\n","      h_union = np.max((ymax, pred_ymax)) - np.min((ymin, pred_ymin))\n","      w_inter = np.min((xmax, pred_xmax)) - np.max((xmin, pred_xmin))\n","      h_inter = np.min((ymax, pred_ymax)) - np.max((ymin, pred_ymin))\n","\n","      w_sub1 = np.abs(xmax - pred_xmax)\n","      h_sub1 = np.abs(ymax - pred_ymax)\n","      w_sub2 = np.abs(xmin - pred_xmin)\n","      h_sub2 = np.abs(ymin - pred_ymin)\n","\n","      iou = (w_inter * h_inter) / ((w_union * h_union) - (w_sub1 * h_sub1) - (w_sub2 * h_sub2))\n","      avg_iou += iou / N_VAL\n","\n","print(avg_iou)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fnWeCeWkHong"},"source":["## 새로운 Image로 Test하기"]},{"cell_type":"code","metadata":{"id":"x2YH9exV9hwF"},"source":["## Image upload 후 실행\n","image = Image.open('xxx.jpg')\n","image = image.resize((224, 224))\n","image = np.array(image)\n","image = image/255."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YcfJ9nXU9huz"},"source":["plt.imshow(image)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSSW6yUMkbBe"},"source":["image.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"coknrANh9hpO"},"source":["image = np.reshape(image, (1, 224, 224, 3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t4p-Otk99hno"},"source":["pred = model.predict(image)\n","print(pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F_QP-J-I9he7"},"source":["## 예측한 BBox 확인\n","prediction = model.predict(image)\n","pred_x = prediction[0,0]\n","pred_y = prediction[0,1]\n","pred_w = prediction[0,2]\n","pred_h = prediction[0,3]\n","pred_xmin = pred_x - pred_w/2.\n","pred_ymin = pred_y - pred_h/2.\n","pred_rect_x = int(pred_xmin * IMG_SIZE)\n","pred_rect_y = int(pred_ymin * IMG_SIZE)\n","pred_rect_w = int(pred_w * IMG_SIZE)\n","pred_rect_h = int(pred_h * IMG_SIZE)\n","\n","pred_rect = Rectangle((pred_rect_x, pred_rect_y), pred_rect_w, pred_rect_h,\n","                      fill=False, color='red')\n","plt.axes().add_patch(pred_rect)\n","\n","plt.imshow(image[0])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xpKlaCjB3LIa"},"source":[""],"execution_count":null,"outputs":[]}]}