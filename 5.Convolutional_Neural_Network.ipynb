{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5.Convolutional_Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTCelnXPkAkk"
      },
      "source": [
        "# Convolutional Neural Network\n",
        "이번 실습에서는 MNIST data를 이용하여 CNN을 학습하고 MLP와 결과를 비교해보겠습니다.\n",
        "\n",
        "또한, 학습된 model을 저장하는 방법을 알아보고,\n",
        "\n",
        "Sequential API 외에 Functional API를 사용하여 model을 만드는 방법에 대해서 알아보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEbpSTxOD-hg"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zZqHgZzkXRj"
      },
      "source": [
        "## 필요한 Library들을 import 합니다\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "## TensorFlow, Keras version 확인\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZofjmrBkd7S"
      },
      "source": [
        "np.random.seed(777)\n",
        "tf.random.set_seed(777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_mzncfzkj6L"
      },
      "source": [
        "## Coding Tips\n",
        "\n",
        "#### 1. Hyper Paramter 정하기\n",
        "#### 2. Data 준비(불러오기 or download 등)\n",
        "#### 3. Dataset 구성 (tf.data.Dataset 이용)\n",
        "#### 4. Modlel 만들기 (Neural Network model)\n",
        "#### 5. Loss function 정의, Optimizer 선택\n",
        "#### 6. Training (Train, Test function 만들기 포함)\n",
        "#### 7. Validation(or Test) 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCLxrff3kfZa"
      },
      "source": [
        "## Hyper-parameters\n",
        "learning_rate = 0.001\n",
        "N_EPOCHS = 20\n",
        "N_BATCH = 100\n",
        "N_CLASS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h7FjkvUkoeK"
      },
      "source": [
        "## MNIST Dataset #########################################################\n",
        "mnist = keras.datasets.mnist\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "##########################################################################\n",
        "\n",
        "## Fashion MNIST Dataset #################################################\n",
        "#mnist = keras.datasets.fashion_mnist\n",
        "#class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "##########################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAO51KEqkq2C"
      },
      "source": [
        "## MNIST dataset load\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAAm2TmLksAS"
      },
      "source": [
        "N_TRAIN = train_images.shape[0]\n",
        "N_TEST = test_images.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiK6TEy8kuI6"
      },
      "source": [
        "# pixel값을 0~1사이 범위로 조정\n",
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "# CNN에 입력으로 넣기 위해 3차원->4차원으로 변경(channel에 1을 추가)\n",
        "train_images = train_images[..., tf.newaxis]\n",
        "test_images = test_images[..., tf.newaxis]\n",
        "# label을 onehot-encoding\n",
        "train_labels = keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = keras.utils.to_categorical(test_labels, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA4JswRpkw0i"
      },
      "source": [
        "## dataset 구성    \n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(\n",
        "                buffer_size=100000).batch(N_BATCH).repeat()\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(N_BATCH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYL3Iw-Ek91j"
      },
      "source": [
        "## Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJr2NE2Uk7li"
      },
      "source": [
        "# Sequential API를 사용하여 model 구성\n",
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='SAME', \n",
        "                                  input_shape=(28, 28, 1)))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.4))\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pofkjKZlByK"
      },
      "source": [
        "## Create model, compile & summary\n",
        "model = create_model()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyq7Yuk-lRNM"
      },
      "source": [
        "## 학습 전에 결과 확인\n",
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDEeZzPGGlhH"
      },
      "source": [
        "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
        "\n",
        "def get_run_logdir():\n",
        "  import time\n",
        "  run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "  return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A3ndVIqlJky"
      },
      "source": [
        "## Parameters for training\n",
        "steps_per_epoch = N_TRAIN//N_BATCH\n",
        "validation_steps = N_TEST//N_BATCH\n",
        "print(steps_per_epoch, validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HnjObb-lLdi"
      },
      "source": [
        "## Training\n",
        "history = model.fit(train_dataset, epochs=N_EPOCHS, steps_per_epoch=steps_per_epoch, \n",
        "                    validation_data=test_dataset, validation_steps=validation_steps,\n",
        "                    callbacks=[tensorboard_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCsnYLKiHDj2"
      },
      "source": [
        "%tensorboard --logdir $run_logdir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxPq_KcOlg_K"
      },
      "source": [
        "## 결과 확인\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.imshow(img[:,:,0],cmap=plt.cm.binary)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    if predicted_label == true_label:\n",
        "        color = 'blue'\n",
        "    else:\n",
        "        color = 'red'\n",
        "\n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "    plt.grid(False)\n",
        "    #plt.xticks([])\n",
        "    plt.xticks(range(N_CLASS), class_names, rotation=90)\n",
        "    plt.yticks([])\n",
        "    thisplot = plt.bar(range(N_CLASS), predictions_array, color=\"#777777\")\n",
        "    plt.ylim([0, 1]) \n",
        "    predicted_label = np.argmax(predictions_array)\n",
        " \n",
        "    thisplot[predicted_label].set_color('red')\n",
        "    thisplot[true_label].set_color('blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA98hUV-lnm5"
      },
      "source": [
        "rnd_idx = np.random.randint(1, N_TEST//N_BATCH)\n",
        "img_cnt = 0\n",
        "for images, labels in test_dataset:\n",
        "    img_cnt += 1\n",
        "    if img_cnt != rnd_idx:\n",
        "        continue\n",
        "    predictions = model(images, training=False)\n",
        "    num_rows = 5\n",
        "    num_cols = 3\n",
        "    num_images = num_rows*num_cols\n",
        "    labels = tf.argmax(labels, axis=-1)\n",
        "    plt.figure(figsize=(3*2*num_cols, 4*num_rows))\n",
        "    plt.subplots_adjust(hspace=1.0)\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "        plot_image(i, predictions.numpy(), labels.numpy(), images.numpy())\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "        plot_value_array(i, predictions.numpy(), labels.numpy())        \n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-In32EFjmBV8"
      },
      "source": [
        "## Weight 저장하고 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CCTzpeOlpq5"
      },
      "source": [
        "## Creating a checkpoint directory\n",
        "cur_dir = os.getcwd()\n",
        "ckpt_dir_name = 'checkpoints'\n",
        "model_dir_name = 'mnist_cnn_keras'\n",
        "ckpt_name = 'mnist_cnn_keras.ckpt'\n",
        "\n",
        "checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_path = os.path.join(checkpoint_dir, ckpt_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPr8-LAwmIjR"
      },
      "source": [
        "## Saving weights\n",
        "model.save_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PkUkZkQmSNJ"
      },
      "source": [
        "## 확인\n",
        "!ls 'checkpoints/mnist_cnn_keras'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxwQQUnTmUjB"
      },
      "source": [
        "## Creating a new model\n",
        "new_model1 = create_model()\n",
        "new_model1.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "new_model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpPHyLmRmgDB"
      },
      "source": [
        "## 학습 전에 결과 확인\n",
        "new_model1.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5h355Eamj4B"
      },
      "source": [
        "rnd_idx = np.random.randint(1, N_TEST//N_BATCH)\n",
        "img_cnt = 0\n",
        "for images, labels in test_dataset:\n",
        "    img_cnt += 1\n",
        "    if img_cnt != rnd_idx:\n",
        "        continue\n",
        "    predictions = new_model1(images, training=False)\n",
        "    num_rows = 5\n",
        "    num_cols = 3\n",
        "    num_images = num_rows*num_cols\n",
        "    labels = tf.argmax(labels, axis=-1)\n",
        "    plt.figure(figsize=(3*2*num_cols, 4*num_rows))\n",
        "    plt.subplots_adjust(hspace=1.0)\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "        plot_image(i, predictions.numpy(), labels.numpy(), images.numpy())\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "        plot_value_array(i, predictions.numpy(), labels.numpy())        \n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9il9M_Vmwnz"
      },
      "source": [
        "## Restore weights\n",
        "new_model1.load_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTpx6xS-m21B"
      },
      "source": [
        "## 결과 확인\n",
        "new_model1.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le1BGl9ym8Vg"
      },
      "source": [
        "rnd_idx = np.random.randint(1, N_TEST//N_BATCH)\n",
        "img_cnt = 0\n",
        "for images, labels in test_dataset:\n",
        "    img_cnt += 1\n",
        "    if img_cnt != rnd_idx:\n",
        "        continue\n",
        "    predictions = new_model1(images, training=False)\n",
        "    num_rows = 5\n",
        "    num_cols = 3\n",
        "    num_images = num_rows*num_cols\n",
        "    labels = tf.argmax(labels, axis=-1)\n",
        "    plt.figure(figsize=(3*2*num_cols, 4*num_rows))\n",
        "    plt.subplots_adjust(hspace=1.0)\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "        plot_image(i, predictions.numpy(), labels.numpy(), images.numpy())\n",
        "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "        plot_value_array(i, predictions.numpy(), labels.numpy())        \n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf2YC7PbnEdk"
      },
      "source": [
        "## Callback 사용하여 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uda4dUrAm_dY"
      },
      "source": [
        "## 새로운 model 생성\n",
        "model = create_model()\n",
        "\n",
        "## model compile\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugndyG4UnN1J"
      },
      "source": [
        "## 학습 전에 결과 확인\n",
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeRpLRxcnRrR"
      },
      "source": [
        "ckpt_name = 'mnist_cnn_{epoch:04d}.ckpt'\n",
        "checkpoint_path = os.path.join(checkpoint_dir, ckpt_name)\n",
        "\n",
        "# callback 만들기\n",
        "cp_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                              save_weights_only=True)\n",
        "\n",
        "## Training\n",
        "history = model.fit(train_dataset, epochs=N_EPOCHS, steps_per_epoch=steps_per_epoch, \n",
        "                    validation_data=test_dataset, validation_steps=validation_steps,\n",
        "                    callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdPXFJk2nfXu"
      },
      "source": [
        "## checkpoint 확인\n",
        "!ls 'checkpoints/mnist_cnn_keras'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTtSU1Ton0j4"
      },
      "source": [
        "## 마지막으로 저장된 checkpoint 불러오기\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gTsZmPsn7P4"
      },
      "source": [
        "# Create a new model instance\n",
        "new_model2 = create_model()\n",
        "new_model2.compile(optimizer=keras.optimizers.Adam(learning_rate),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "# Before loading weights\n",
        "new_model2.evaluate(test_dataset)\n",
        "\n",
        "# Load the previously saved weights\n",
        "new_model2.load_weights(latest)\n",
        "\n",
        "# Re-evaluate the model\n",
        "new_model2.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1jfAa-tpKc9"
      },
      "source": [
        "## 전체 model 저장하고 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDb0Y25SpMMW"
      },
      "source": [
        "## HDF5 format으로 전체 model 저장하기\n",
        "save_dir_name = 'saved_models'\n",
        "os.makedirs(save_dir_name, exist_ok=True)\n",
        "hdf5_model_path = os.path.join(cur_dir, save_dir_name, 'my_model.h5')\n",
        "hdf5_model_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2oLSYuLpb45"
      },
      "source": [
        "## 저장\n",
        "model.save(hdf5_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhLViRxCpeIo"
      },
      "source": [
        "## 확인\n",
        "!ls saved_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bztde8kpglw"
      },
      "source": [
        "## 불러오기\n",
        "new_model3 = keras.models.load_model(hdf5_model_path)\n",
        "\n",
        "new_model3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjQULLtvppMq"
      },
      "source": [
        "## 결과 확인\n",
        "new_model3.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZFt6i--puBY"
      },
      "source": [
        "## saved_model format으로 전체 model 저장하기\n",
        "saved_model_path = os.path.join(cur_dir, save_dir_name, 'my_model')\n",
        "\n",
        "model.save(saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5JcSgYdqD9e"
      },
      "source": [
        "## 확인\n",
        "!ls 'saved_models/my_model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jisZS4KHqJxP"
      },
      "source": [
        "## 불러오기\n",
        "new_model4 = keras.models.load_model(saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFa9hInBqf_A"
      },
      "source": [
        "## 결과 확인\n",
        "new_model4.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCnAteWLq74L"
      },
      "source": [
        "## Functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfvB1bVwqjAP"
      },
      "source": [
        "# Functional API를 사용하여 model 구성\n",
        "def create_model():\n",
        "    inputs = keras.Input(shape=(28, 28, 1))\n",
        "    conv1 = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding='SAME', activation='relu')(inputs)\n",
        "    pool1 = keras.layers.MaxPool2D(padding='SAME')(conv1)\n",
        "    conv2 = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation='relu')(pool1)\n",
        "    pool2 = keras.layers.MaxPool2D(padding='SAME')(conv2)\n",
        "    conv3 = keras.layers.Conv2D(filters=128, kernel_size=[3, 3], padding='SAME', activation='relu')(pool2)\n",
        "    pool3 = keras.layers.MaxPool2D(padding='SAME')(conv3)\n",
        "    pool3_flat = keras.layers.Flatten()(pool3)\n",
        "    dense4 = keras.layers.Dense(units=256, activation='relu')(pool3_flat)\n",
        "    drop4 = keras.layers.Dropout(rate=0.4)(dense4)\n",
        "    logits = keras.layers.Dense(units=10, activation='softmax')(drop4)\n",
        "    return keras.Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvvgS90lq_5H"
      },
      "source": [
        "## Create model, compile & summary\n",
        "model = create_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0pdHvtbrKhR"
      },
      "source": [
        "## 학습 전에 결과 확인\n",
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MGma-9mrNwn"
      },
      "source": [
        "## Training\n",
        "history = model.fit(train_dataset, epochs=N_EPOCHS, steps_per_epoch=steps_per_epoch, \n",
        "                    validation_data=test_dataset, validation_steps=validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXF-QkW6rRUX"
      },
      "source": [
        "## model 저장하고 불러오기\n",
        "## HDF5 format\n",
        "saved_model_path = os.path.join(cur_dir, save_dir_name, 'mnist_cnn_func.h5')\n",
        "model.save(saved_model_path)\n",
        "!ls saved_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XZGdqFLrf9O"
      },
      "source": [
        "new_model5 = keras.models.load_model(saved_model_path)\n",
        "new_model5.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoVYbcOgrheg"
      },
      "source": [
        "## saved_model format\n",
        "saved_model_path = os.path.join(cur_dir, save_dir_name, 'mnist_cnn_func_pb')\n",
        "model.save(saved_model_path)\n",
        "!ls -l saved_models/mnist_cnn_func_pb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d58eftYhrqJx"
      },
      "source": [
        "new_model6 = keras.models.load_model(saved_model_path)\n",
        "new_model6.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB2WIirYYk0q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}