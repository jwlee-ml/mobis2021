{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11.Oxford_Pet_Segmentation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Do9e8cnKiFhm"},"source":["## library import\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import os\n","import re\n","from PIL import Image\n","import shutil\n","import random\n","import matplotlib.pyplot as plt\n","\n","print(tf.__version__)\n","print(keras.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FwbGSntkEqoJ"},"source":["## Data 준비하기"]},{"cell_type":"code","metadata":{"id":"IEsSkAPzjkqt"},"source":["## google drive에서 압축된 dataset download\n","import gdown\n","url = 'https://drive.google.com/uc?id=1dIR9ANjUsV9dWa0pS9J0c2KUGMfpIRG0'\n","fname = 'oxford_pet.zip'\n","gdown.download(url, fname, quiet=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"26RsVgfjk4f5"},"source":["## oxford_pet.zip이 보이는지 확인\n","!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfMOW1tok6jU"},"source":["## 압축풀기\n","!unzip -q oxford_pet.zip -d oxford_pet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7cgzR9Swk70U"},"source":["## 압축이 풀린 directory 확인\n","!ls oxford_pet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fazkGgbzlAw0"},"source":["## directory 정보\n","cur_dir = os.getcwd()\n","data_dir = os.path.join(cur_dir, 'oxford_pet')\n","image_dir = os.path.join(data_dir, 'images')\n","#bbox_dir = os.path.join(data_dir, 'annotations', 'xmls')\n","seg_dir = os.path.join(data_dir, 'annotations', 'trimaps')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0EfLhDTqHLU"},"source":["## image file 수 확인\n","image_files = [fname for fname in os.listdir(image_dir) if os.path.splitext(fname)[-1] == '.jpg']\n","print(len(image_files))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l1jHcBgRDNsn"},"source":["## segmentation을 위한 annotation이 되어 있는 file의 수 확인\n","seg_files = [fname for fname in os.listdir(seg_dir) if os.path.splitext(fname)[-1] == '.png']\n","len(seg_files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-A9mBvDQon8a"},"source":["## image file들을 읽어서 channel이 3이 아닌 image는 삭제, xml도 같이 삭제\n","for image_file in image_files:\n","  image_path = os.path.join(image_dir, image_file)\n","  seg_file = os.path.splitext(image_file)[0]+'.png'\n","  seg_path = os.path.join(seg_dir, seg_file)\n","  image = Image.open(image_path)\n","  image_mode = image.mode\n","  if image_mode != 'RGB':\n","    print(image_file, image_mode)\n","    image = np.asarray(image)\n","    print(image.shape)\n","    os.remove(image_path)\n","    os.remove(seg_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"znKgQwWPqEs5"},"source":["## image file 수 확인\n","image_files = [fname for fname in os.listdir(image_dir) if os.path.splitext(fname)[-1] == '.jpg']\n","print(len(image_files))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RiwM54x6zeqY"},"source":["## segmentation을 위한 annotation이 되어 있는 file의 수 확인\n","seg_files = [fname for fname in os.listdir(seg_dir) if os.path.splitext(fname)[-1] == '.png']\n","len(seg_files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZjj198gzg8k"},"source":["class_list = set()\n","for image_file in image_files:\n","    file_name = os.path.splitext(image_file)[0]\n","    class_name = re.sub('_\\d+', '', file_name)\n","    class_list.add(class_name)\n","class_list = list(class_list)\n","print(len(class_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YJpqthm_rq4p"},"source":["class_list.sort()\n","class_list[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LBrcB1D_54jq"},"source":["class2idx = {cls:idx for idx, cls in enumerate(class_list)}\n","class2idx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-4qywtHHO1oq"},"source":["## train, validation directory 생성\n","train_dir = os.path.join(data_dir, 'train')\n","val_dir = os.path.join(data_dir, 'validation')\n","os.makedirs(train_dir, exist_ok=True)\n","os.makedirs(val_dir, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CkkIWMLqO1uv"},"source":["image_files.sort()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nk0sB8XlO2B4"},"source":["image_files[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MfUao2KKO2FI"},"source":["cnt = 0\n","previous_class = \"\"\n","for image_file in image_files:\n","    file_name = os.path.splitext(image_file)[0]\n","    class_name = re.sub('_\\d+', '', file_name)\n","    if class_name == previous_class:\n","        cnt += 1\n","    else:\n","        cnt = 1\n","    if cnt <= 160:\n","        cpath = train_dir\n","    else:\n","        cpath = val_dir\n","    image_path = os.path.join(image_dir, image_file)\n","    shutil.copy(image_path, cpath)\n","    previous_class = class_name"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MVv3FhZaO5zw"},"source":["train_images = os.listdir(train_dir)\n","val_images = os.listdir(val_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I6WHydVRO52y"},"source":["print(len(train_images), len(val_images))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AKUKfUdiO556"},"source":["train_images[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t8zs6BUTO1sG"},"source":["val_images[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Twz3WE4P9d7"},"source":["# 임의의 image를 가져와서, seg map 확인\n","fnames = os.listdir(val_dir)\n","rnd_idx = random.randint(0, len(fnames)-1)\n","fname = fnames[rnd_idx]\n","\n","fpath = os.path.join(val_dir, fname)\n","img = Image.open(fpath)\n","img = np.array(img)\n","\n","## segmentation label\n","## 원래 label은 1: foreground, 2: background, 3: not classified 로 구성됨\n","## 이것을 0: background, 1 : foreground & not classified로 변경\n","sname = os.path.splitext(fname)[0] + '.png'\n","spath = os.path.join(seg_dir, sname)    \n","seg = Image.open(spath)\n","seg = np.array(seg)\n","#seg[seg>2] = 1\n","#seg[seg==2] = 0\n","\n","plt.figure(figsize=(10, 4))\n","plt.subplot(1, 2, 1)\n","plt.imshow(img)\n","plt.subplot(1, 2, 2)\n","plt.imshow(seg)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YBVTka-OJ3iP"},"source":["seg[seg>2] = 1\n","seg[seg==2] = 0\n","\n","plt.figure(figsize=(10, 4))\n","plt.subplot(1, 2, 1)\n","plt.imshow(img)\n","plt.subplot(1, 2, 2)\n","plt.imshow(seg)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9vC1-oTvEwK9"},"source":["## TFRecord 만들기"]},{"cell_type":"code","metadata":{"id":"6ADxeVGrys37"},"source":["IMG_SIZE = 224\n","N_TRAIN = len(train_images)\n","N_VAL = len(val_images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQoIKWbfytPq"},"source":["## TFRecord 저장할 directory와 file 경로 설정\n","tfr_dir = os.path.join(data_dir, 'tfrecord')\n","os.makedirs(tfr_dir, exist_ok=True)\n","\n","tfr_train_dir = os.path.join(tfr_dir, 'seg_train.tfr')\n","tfr_val_dir = os.path.join(tfr_dir, 'seg_val.tfr')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0MjxRm8Ky6gz"},"source":["## TFRecord writer 생성\n","writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n","writer_val = tf.io.TFRecordWriter(tfr_val_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J_ndom94ytXR"},"source":["# The following functions can be used to convert a value to a type compatible\n","# with tf.Example.\n","\n","def _bytes_feature(value):\n","  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","  if isinstance(value, type(tf.constant(0))):\n","    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n","  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _float_feature(value):\n","  \"\"\"Returns a float_list from a float / double.\"\"\"\n","  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n","\n","def _int64_feature(value):\n","  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DikBpr9Ww65h"},"source":["n_train = 0\n","\n","train_files = os.listdir(train_dir)\n","for train_file in train_files:\n","  train_path = os.path.join(train_dir, train_file)\n","  image = Image.open(train_path)\n","  image = image.resize((IMG_SIZE, IMG_SIZE))\n","  bimage = image.tobytes()\n","\n","  file_name = os.path.splitext(train_file)[0] #Bangal_101\n","  class_name = re.sub('_\\d+', '', file_name)\n","  class_num = class2idx[class_name]\n","\n","  if file_name[0].islower(): # dog\n","    bi_cls_num = 0\n","  else: # cat\n","    bi_cls_num = 1\n","\n","  seg_name = file_name + '.png'\n","  seg_path = os.path.join(seg_dir, seg_name)\n","  seg = Image.open(seg_path)\n","  seg = seg.resize((IMG_SIZE, IMG_SIZE))\n","  seg = np.array(seg)\n","  seg[seg>2] = 1\n","  seg[seg==2] = 0\n","  bseg = seg.tobytes()\n","\n","  example = tf.train.Example(features=tf.train.Features(feature={\n","      'image': _bytes_feature(bimage),\n","      'cls_num': _int64_feature(class_num),\n","      'bi_cls_num': _int64_feature(class_num),\n","      'seg': _bytes_feature(bseg)\n","  }))\n","  writer_train.write(example.SerializeToString())\n","  n_train += 1\n","\n","writer_train.close()\n","print(n_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HfTv8QUKyNtD"},"source":["n_val = 0\n","\n","val_files = os.listdir(val_dir)\n","for val_file in val_files:\n","  val_path = os.path.join(val_dir, val_file)\n","  image = Image.open(val_path)\n","  image = image.resize((IMG_SIZE, IMG_SIZE))\n","  bimage = image.tobytes()\n","\n","  file_name = os.path.splitext(val_file)[0] #Bangal_101\n","  class_name = re.sub('_\\d+', '', file_name)\n","  class_num = class2idx[class_name]\n","\n","  if file_name[0].islower(): # dog\n","    bi_cls_num = 0\n","  else: # cat\n","    bi_cls_num = 1\n","\n","  seg_name = file_name + '.png'\n","  seg_path = os.path.join(seg_dir, seg_name)\n","  seg = Image.open(seg_path)\n","  seg = seg.resize((IMG_SIZE, IMG_SIZE))\n","  seg = np.array(seg)\n","  seg[seg>2] = 1\n","  seg[seg==2] = 0\n","  bseg = seg.tobytes()\n","\n","  example = tf.train.Example(features=tf.train.Features(feature={\n","      'image': _bytes_feature(bimage),\n","      'cls_num': _int64_feature(class_num),\n","      'bi_cls_num': _int64_feature(class_num),\n","      'seg': _bytes_feature(bseg)\n","  }))\n","  writer_val.write(example.SerializeToString())\n","  n_val += 1\n","\n","writer_val.close()\n","print(n_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"twz9lD1SI2Y0"},"source":["## Segmentation"]},{"cell_type":"code","metadata":{"id":"eQz4UdD_yQWB"},"source":["## Hyper Parameters\n","N_CLASS = len(class_list)\n","N_EPOCHS = 20\n","N_BATCH = 40\n","IMG_SIZE = 224\n","learning_rate = 0.0001\n","steps_per_epoch = N_TRAIN / N_BATCH\n","validation_steps = int(np.ceil(N_VAL / N_BATCH))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfPlRmaByUrJ"},"source":["## tfrecord file을 data로 parsing해주는 function\n","def _parse_function(tfrecord_serialized):\n","    features={'image': tf.io.FixedLenFeature([], tf.string),\n","              'cls_num': tf.io.FixedLenFeature([], tf.int64),\n","              'bi_cls_num': tf.io.FixedLenFeature([], tf.int64),\n","              'seg': tf.io.FixedLenFeature([], tf.string)              \n","             }\n","    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n","    \n","    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)    \n","    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 3])\n","    image = tf.cast(image, tf.float32)/255.\n","\n","    cls_label = tf.cast(parsed_features['cls_num'], tf.int64)\n","    bi_cls_label = tf.cast(parsed_features['bi_cls_num'], tf.int64)\n","    \n","    seg = tf.io.decode_raw(parsed_features['seg'], tf.uint8)    \n","    seg = tf.reshape(seg, [IMG_SIZE, IMG_SIZE, -1])\n","    seg = tf.cast(seg, tf.float32)\n","    \n","    return image, seg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sp4sPRxx6CrZ"},"source":["## train dataset 만들기\n","train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n","train_dataset = train_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","train_dataset = train_dataset.shuffle(buffer_size=N_TRAIN).prefetch(\n","    tf.data.experimental.AUTOTUNE).batch(N_BATCH).repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QacNfsYQ6PBH"},"source":["## validation dataset 만들기\n","val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n","val_dataset = val_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","val_dataset = val_dataset.batch(N_BATCH).repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5_CwlDAV6R92"},"source":["## train dataset에서 1개의 image와 bbox를 읽어서 확인\n","for image, seg in val_dataset.take(3):\n","  plt.figure(figsize=(11,5))\n","  plt.subplot(1,2,1)\n","  plt.imshow(image[0])\n","  plt.subplot(1,2,2)\n","  plt.imshow(seg[0,:,:,0])\n","  plt.show()   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6pNW77yJe-L"},"source":["## U-Net like model에 pretrained VGG를 활용하여 학습하기"]},{"cell_type":"code","metadata":{"id":"1GWuNkRBNi57"},"source":["from tensorflow.keras.utils import get_file"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkMceED6SthA"},"source":["## vgg16 pretrained weights 다운로드\n","weight_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n","                      'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UH6BE9kzCDED"},"source":["from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, ReLU, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D, Concatenate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zkl-ba83Svs1"},"source":["def create_model():\n","    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n","    \n","    conv1_1 = Conv2D(64, 3, 1, 'SAME', activation='relu')(inputs)\n","    conv1_2 = Conv2D(64, 3, 1, 'SAME', activation='relu')(conv1_1)\n","    pool1_3 = MaxPooling2D()(conv1_2)\n","    \n","    conv2_1 = Conv2D(128, 3, 1, 'SAME', activation='relu')(pool1_3)\n","    conv2_2 = Conv2D(128, 3, 1, 'SAME', activation='relu')(conv2_1)\n","    pool2_3 = MaxPooling2D()(conv2_2)\n","    \n","    conv3_1 = Conv2D(256, 3, 1, 'SAME', activation='relu')(pool2_3)\n","    conv3_2 = Conv2D(256, 3, 1, 'SAME', activation='relu')(conv3_1)\n","    conv3_3 = Conv2D(256, 3, 1, 'SAME', activation='relu')(conv3_2)\n","    pool3_4 = MaxPooling2D()(conv3_3)\n","    \n","    conv4_1 = Conv2D(512, 3, 1, 'SAME', activation='relu')(pool3_4)\n","    conv4_2 = Conv2D(512, 3, 1, 'SAME', activation='relu')(conv4_1)\n","    conv4_3 = Conv2D(512, 3, 1, 'SAME', activation='relu')(conv4_2)\n","    pool4_4 = MaxPooling2D()(conv4_3)\n","    \n","    conv5_1 = Conv2D(512, 3, 1, 'SAME', activation='relu')(pool4_4)\n","    conv5_2 = Conv2D(512, 3, 1, 'SAME', activation='relu')(conv5_1)\n","    conv5_3 = Conv2D(512, 3, 1, 'SAME', activation='relu')(conv5_2)\n","    pool5_4 = MaxPooling2D()(conv5_3)\n","    \n","    ## loading vgg16 pretrained weights\n","    vgg = keras.Model(inputs, pool5_4)\n","    vgg.load_weights(weight_path)\n","    \n","    upconv6 = Conv2DTranspose(512, 5, 2, 'SAME', activation='relu')(pool5_4)\n","    concat6 = Concatenate()([conv5_3, upconv6])\n","    conv6 = Conv2D(512, 3, 1, 'SAME', activation='relu')(concat6)\n","                              \n","    upconv7 = Conv2DTranspose(512, 5, 2, 'SAME', activation='relu')(conv6)\n","    concat7 = Concatenate()([conv4_3, upconv7])\n","    conv7 = Conv2D(512, 3, 1, 'SAME', activation='relu')(concat7)\n","    \n","    upconv8 = Conv2DTranspose(256, 5, 2, 'SAME', activation='relu')(conv7)\n","    concat8 = Concatenate()([conv3_3, upconv8])\n","    conv8 = Conv2D(256, 3, 1, 'SAME', activation='relu')(concat8)\n","    \n","    upconv9 = Conv2DTranspose(128, 5, 2, 'SAME', activation='relu')(conv8)\n","    concat9 = Concatenate()([conv2_2, upconv9])\n","    conv9 = Conv2D(128, 3, 1, 'SAME', activation='relu')(concat9)\n","    \n","    upconv10 = Conv2DTranspose(64, 5, 2, 'SAME', activation='relu')(conv9)\n","    concat10 = Concatenate()([conv1_2, upconv10])\n","    conv10 = Conv2D(64, 3, 1, 'SAME', activation='relu')(concat10)\n","    \n","    conv11 = Conv2D(64, 3, 1, 'SAME', activation='relu')(conv10)\n","    \n","    conv12 = Conv2D(2, 1, 1, 'SAME', activation='softmax')(conv11)\n","    \n","    return keras.Model(inputs=inputs, outputs=conv12) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_wkCcKmVSyqh"},"source":["model = create_model()\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIp5QzbwS3JN"},"source":["## learning rate scheduing\n","lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n","                                                          decay_steps=steps_per_epoch*10,\n","                                                          decay_rate=0.4,\n","                                                          staircase=True)\n","## optimizer는 Adam, loss는 sparse categorical crossentropy 사용\n","## label이 ont-hot으로 encoding 안 된 경우에 sparse categorical corssentropy 및 sparse categorical accuracy 사용\n","model.compile(keras.optimizers.Adam(lr_schedule), loss='sparse_categorical_crossentropy',\n","             metrics=['sparse_categorical_accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sr9kfTvoS5yT"},"source":["## Train!\n","model.fit(train_dataset, steps_per_epoch=steps_per_epoch,\n","         epochs=N_EPOCHS,\n","         validation_data=val_dataset,\n","         validation_steps=validation_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o8ylGjJES9QW"},"source":["## num_imgs만큼 validation dataset에서 읽어서 정답과 예측값 확인\n","num_imgs = 10\n","idx = 0\n","for image, seg in val_dataset.take(num_imgs):\n","    plt.figure(figsize=(17, 6*num_imgs))\n","    plt.subplot(num_imgs,3,idx*3+1)\n","    plt.imshow(image[0])\n","    plt.subplot(num_imgs,3,idx*3+2)\n","    plt.imshow(seg[0,:,:,0], vmin=0, vmax=1)\n","\n","    plt.subplot(num_imgs,3,idx*3+3)\n","    ## validation data에 대한 예측값 생성\n","    prediction = model.predict(image)    \n","    pred = np.zeros_like(prediction)\n","    ## 0.5이상은 1로 나머지는 0으로 변환\n","    thr = 0.5\n","    pred[prediction>=thr] = 1\n","    pred[prediction<thr] = 0\n","    plt.imshow(pred[0,:,:,1])\n","    plt.show() \n","    idx += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1BRjvtgO1Ra6"},"source":["## IOU 계산\n","avg_iou = 0\n","n = 0\n","for images, labels in val_dataset.take(validation_steps):  \n","  preds = model.predict(images)\n","  preds[preds>=0.5] = 1\n","  preds[preds<0.5] = 0\n","\n","  psum = labels[...,0] + preds[...,1]\n","\n","  union = np.array(psum)\n","  union[union>1] = 1.\n","  union = np.sum(union, axis=1)\n","  union = np.sum(union, axis=1)\n","\n","  inter = np.array(psum)\n","  inter[inter==1] = 0.\n","  inter[inter>1] = 1.  \n","  inter = np.sum(inter, axis=1)\n","  inter = np.sum(inter, axis=1)\n","  \n","  iou = inter / union  \n","  avg_iou += np.sum(iou) / N_VAL\n","\n","print(avg_iou)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5vTza88XJqqW"},"source":["## 새로운 Image로 Test하기"]},{"cell_type":"code","metadata":{"id":"worY3byJS_aV"},"source":["## Image upload 후 실행\n","image = Image.open('chi.jpg')\n","image = image.resize((224, 224))\n","image = np.array(image)\n","image = image/255."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_8cEz1naPhc"},"source":["plt.imshow(image)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bWa-_V8HaSDB"},"source":["image = np.reshape(image, (1, 224, 224, 3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzXiewHHaTtp"},"source":["prediction = model.predict(image)\n","prediction.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"571T53M6a2lU"},"source":["pred = np.zeros_like(prediction)\n","## 0.5이상은 1로 나머지는 0으로 변환\n","thr = 0.5\n","pred[prediction>=thr] = 1\n","pred[prediction<thr] = 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lNhvuLknaYkT"},"source":["## 예측 결과 확인\n","plt.figure(figsize=(11,5))\n","plt.subplot(1,2,1)\n","plt.imshow(image[0])\n","plt.subplot(1,2,2)\n","plt.imshow(pred[0,:,:,1])\n","plt.show()  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8QOKofRw2TkQ"},"source":[""],"execution_count":null,"outputs":[]}]}