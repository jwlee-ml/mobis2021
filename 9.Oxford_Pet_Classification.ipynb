{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"9.Oxford_Pet_Classification.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WOlR5SRQ_rRn"},"source":["## library import\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import os\n","import re\n","from PIL import Image\n","import shutil\n","from sklearn.model_selection import train_test_split\n","import random\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0q3wx3rfAKD9"},"source":["print(tf.__version__)\n","print(keras.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"INMNWadsDycA"},"source":["## Data 준비"]},{"cell_type":"code","metadata":{"id":"zu7sQGmLANhW"},"source":["## google drive에서 압축된 dataset download\n","import gdown\n","url = 'https://drive.google.com/uc?id=1dIR9ANjUsV9dWa0pS9J0c2KUGMfpIRG0'\n","fname = 'oxford_pet.zip'\n","gdown.download(url, fname, quiet=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDkv_v3rASc2"},"source":["## oxford_pet.zip이 보이는지 확인\n","!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DdYtua7-AZw2"},"source":["## 압축풀기\n","!unzip -q oxford_pet.zip -d oxford_pet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xWlYo19mAckW"},"source":["## 압축이 풀린 directory 확인\n","!ls oxford_pet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oUP8ce30AhSe"},"source":["## directory 설정\n","cur_dir = os.getcwd()\n","data_dir = os.path.join(cur_dir, 'oxford_pet')\n","image_dir = os.path.join(data_dir, 'images')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CN8xhsaAAjj2"},"source":["## image file 수 확인\n","image_files = [fname for fname in os.listdir(image_dir) if os.path.splitext(fname)[-1] == '.jpg']\n","print(len(image_files))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTDYdL5dAlCm"},"source":["## image file들을 읽어서 channel이 3이 아닌 image는 삭제\n","for image_file in image_files:\n","  image_path = os.path.join(image_dir, image_file)\n","  image = Image.open(image_path)\n","  image_mode = image.mode\n","  if image_mode != 'RGB':\n","    print(image_file, image_mode)\n","    image = np.asarray(image)\n","    print(image.shape)\n","    os.remove(image_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cppg8h2VAw4Z"},"source":["## image file 수 확인\n","image_files = [fname for fname in os.listdir(image_dir) if os.path.splitext(fname)[-1] == '.jpg']\n","print(len(image_files))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"222XfHgfBEn8"},"source":["class_list = set()\n","for image_file in image_files:\n","    file_name = os.path.splitext(image_file)[0]\n","    class_name = re.sub('_\\d+', '', file_name)\n","    class_list.add(class_name)\n","class_list = list(class_list)\n","print(len(class_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xgAn11sPBoCk"},"source":["class_list.sort()\n","class_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSR0PnMuB-RB"},"source":["class_list[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JSD0OPZiBqcW"},"source":["class2idx = {cls:idx for idx, cls in enumerate(class_list)}\n","class2idx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"28uLAxq7B28m"},"source":["class2idx['Bengal']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dYVLpAqbCDVD"},"source":["## train, validation directory 생성\n","train_dir = os.path.join(data_dir, 'train')\n","val_dir = os.path.join(data_dir, 'validation')\n","os.makedirs(train_dir, exist_ok=True)\n","os.makedirs(val_dir, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BvTqU94CNDI"},"source":["image_files.sort()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_bWy45HtCRfu"},"source":["image_files[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vtk6sPRCSmG"},"source":["cnt = 0\n","previous_class = \"\"\n","for image_file in image_files:\n","    file_name = os.path.splitext(image_file)[0]\n","    class_name = re.sub('_\\d+', '', file_name)\n","    if class_name == previous_class:\n","        cnt += 1\n","    else:\n","        cnt = 1\n","    if cnt <= 160:\n","        cpath = train_dir\n","    else:\n","        cpath = val_dir\n","    image_path = os.path.join(image_dir, image_file)\n","    shutil.copy(image_path, cpath)\n","    previous_class = class_name"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hBFCxHS4DUPZ"},"source":["train_images = os.listdir(train_dir)\n","val_images = os.listdir(val_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QozFeSbWDXtW"},"source":["print(len(train_images), len(val_images))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hkE29AuyDZke"},"source":["train_images[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LWM5lj9-DbKz"},"source":["val_images[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k346RhAjDtZp"},"source":["## TFRecord File 만들기"]},{"cell_type":"code","metadata":{"id":"69VyTmqqDc2b"},"source":["IMG_SIZE = 224"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qa4QauQ7DsCp"},"source":["## TFRecord 저장할 directory와 file 경로 설정\n","tfr_dir = os.path.join(data_dir, 'tfrecord')\n","os.makedirs(tfr_dir, exist_ok=True)\n","\n","tfr_train_dir = os.path.join(tfr_dir, 'cls_train.tfr')\n","tfr_val_dir = os.path.join(tfr_dir, 'cls_val.tfr')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7D2rJ_WQD7wh"},"source":["## TFRecord writer 생성\n","writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n","writer_val = tf.io.TFRecordWriter(tfr_val_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X9C7LmF3Fl4Q"},"source":["# The following functions can be used to convert a value to a type compatible\n","# with tf.Example.\n","\n","def _bytes_feature(value):\n","  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n","  if isinstance(value, type(tf.constant(0))):\n","    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n","  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n","\n","def _float_feature(value):\n","  \"\"\"Returns a float_list from a float / double.\"\"\"\n","  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n","\n","def _int64_feature(value):\n","  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n","  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XrDR5d2SGZBY"},"source":["## Training data로 tfrecord 만들기\n","n_train = 0\n","\n","train_files = os.listdir(train_dir)\n","for train_file in train_files:\n","  train_path = os.path.join(train_dir, train_file)\n","  image = Image.open(train_path)\n","  image = image.resize((IMG_SIZE, IMG_SIZE))\n","  bimage = image.tobytes()\n","\n","  file_name = os.path.splitext(train_file)[0] #Bangal_101\n","  class_name = re.sub('_\\d+', '', file_name)\n","  class_num = class2idx[class_name]\n","\n","  example = tf.train.Example(features=tf.train.Features(feature={\n","      'image': _bytes_feature(bimage),\n","      'cls_num': _int64_feature(class_num)\n","  }))\n","  writer_train.write(example.SerializeToString())\n","  n_train += 1\n","\n","writer_train.close()\n","print(n_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0HL5fAeHm7Q"},"source":["## Validation data로 tfrecord 만들기\n","n_val = 0\n","\n","val_files = os.listdir(val_dir)\n","for val_file in val_files:\n","  val_path = os.path.join(val_dir, val_file)\n","  image = Image.open(val_path)\n","  image = image.resize((IMG_SIZE, IMG_SIZE))\n","  bimage = image.tobytes()\n","\n","  file_name = os.path.splitext(val_file)[0] #Bangal_101\n","  class_name = re.sub('_\\d+', '', file_name)\n","  class_num = class2idx[class_name]\n","\n","  example = tf.train.Example(features=tf.train.Features(feature={\n","      'image': _bytes_feature(bimage),\n","      'cls_num': _int64_feature(class_num)\n","  }))\n","  writer_val.write(example.SerializeToString())\n","  n_val += 1\n","\n","writer_val.close()\n","print(n_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z1JBx-YMH8iP"},"source":["!ls -l $tfr_dir"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T9l6lGpGJA0a"},"source":["## Classification"]},{"cell_type":"code","metadata":{"id":"q67RpcOWIHk3"},"source":["## Hyper Parameters\n","N_CLASS = len(class_list)\n","N_EPOCHS = 15\n","N_BATCH = 40\n","N_TRAIN = n_train\n","N_VAL = n_val\n","IMG_SIZE = 224\n","learning_rate = 0.0001\n","steps_per_epoch = N_TRAIN / N_BATCH\n","validation_steps = int(np.ceil(N_VAL / N_BATCH))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ItNVoidIQNQ"},"source":["## tfrecord file을 data로 parsing해주는 function\n","def _parse_function(tfrecord_serialized):\n","    features={'image': tf.io.FixedLenFeature([], tf.string),\n","              'cls_num': tf.io.FixedLenFeature([], tf.int64)              \n","             }\n","    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n","    \n","    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)    \n","    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 3])\n","    image = tf.cast(image, tf.float32)/255. \n","\n","    label = tf.cast(parsed_features['cls_num'], tf.int64)\n","\n","    return image, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6g4htxQRIsPv"},"source":["## train dataset 만들기\n","train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n","train_dataset = train_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","train_dataset = train_dataset.shuffle(N_TRAIN).prefetch(\n","    tf.data.experimental.AUTOTUNE).batch(N_BATCH).repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zP6T4iHwJK3n"},"source":["## validation dataset 만들기\n","val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n","val_dataset = val_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","val_dataset = val_dataset.batch(N_BATCH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XS8zrviiJMEq"},"source":["for image, label in train_dataset.take(5):\n","  plt.imshow(image[0])\n","  title = class_list[label[0].numpy()]\n","  plt.title(title)\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9PoII6syeJO4"},"source":["### Pretrained MobileNetV2 사용하여 학습하기"]},{"cell_type":"code","metadata":{"id":"Hb0-ZgBEeNNA"},"source":["from tensorflow.keras import models\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n","from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vy6BRv5eQIK"},"source":["mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5iMMVs1WeRpr"},"source":["mobilenetv2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tQgIKM1CeVbQ"},"source":["def create_mv_model():\n","  model = models.Sequential()\n","  model.add(mobilenetv2)\n","  model.add(GlobalAveragePooling2D())  \n","  model.add(Dense(N_CLASS, activation='softmax'))\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gjw_rYd1edcp"},"source":["## Create model, compile & summary\n","model = create_mv_model()\n","\n","## learning rate scheduing\n","lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n","                                                          decay_steps=steps_per_epoch*5,\n","                                                          decay_rate=0.5,\n","                                                          staircase=True)\n","model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R3AqznXIeerq"},"source":["history = model.fit(\n","    train_dataset,\n","    epochs=N_EPOCHS,\n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=val_dataset,\n","    validation_steps=validation_steps\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fnWeCeWkHong"},"source":["## 새로운 Image로 Test하기"]},{"cell_type":"code","metadata":{"id":"x2YH9exV9hwF"},"source":["## Image upload 후 실행\n","image = Image.open('xxx.jpg')\n","image = image.resize((224, 224))\n","image = np.array(image)\n","image = image/255."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YcfJ9nXU9huz"},"source":["plt.imshow(image)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSSW6yUMkbBe"},"source":["image.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"coknrANh9hpO"},"source":["image = np.reshape(image, (1, 224, 224, 3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t4p-Otk99hno"},"source":["pred = model.predict(image)\n","print(pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uHPouJrJFH-Y"},"source":["class_num = np.argmax(pred, axis=-1)\n","print(\"CNN이 예측한 class name은 {} 입니다.\".format(class_list[class_num]))"],"execution_count":null,"outputs":[]}]}